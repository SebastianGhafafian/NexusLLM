{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Nowadays, the world revolves around data. We created elaborate infrastructures, namely databases, to interact with the data in efficient ways. Yet, this requires more sophisticates techniques like mastering SQL access the data, which locks away information for people that lack knowledge of SQL. Currently, Large Language Models (LLMs) are becomming more and more popluar for interaction with databases enabling everyone to gain insights using the databases content. This short project looks into LLMs how they can call function by providing precise arguments helping to to interact with databases. \n",
    "This project has two parts:\n",
    "* First, we'll let a LLM interact with a dataset generating features like a sentiment of a dialogue and names of involved persons. It uses the LLM capabilty of function calling to built a dialgue processing system. \n",
    "* The second part explores the ability of an LLM to interact with databases by creating increasingly more complex question and analyzing typical hallucinations.\n",
    " \n",
    "I used  Nexus Raven for this project. It has 13B parameter, yet it is specifically trained on python code to enhance the performance in calling functions. If you want to find out more, check out their [course](https://www.deeplearning.ai/short-courses/function-calling-and-data-extraction-with-llms/) on Deeplearning.ai.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "The Customer Service dataset used in this project is freely available from [HuggingFace](https://huggingface.co/datasets/SantiagoPG/customer_service_chatbot). It contains 1000 records of interactions of customers and customer service containing data about the type of issue, product category and more. I will be focussing on the conversation dialogue that happened between both parties. This allows for interesting applications of LLMs to extract features from text.\n",
    "\n",
    "The other database I used in the project is the Chinook database. It contains several tables which allows to build more ellaborate SQL queries including joins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Using LLM to interact with the data to create a new dataset\n",
    "\n",
    "The first part follows the following steps:\n",
    "* Load the data set and get an overview of the data\n",
    "* Creating a data class to define desired outputs from the dialogues\n",
    "* Initializing a test database to store extracted data\n",
    "* Creating prompts for the LLM to fill instances of the data class and to upload it to the database\n",
    "* Testing the function using the test data base\n",
    "* Creating a database for the second part of the project\n",
    "\n",
    "## Loading the data\n",
    "Let's have a quick look at the customer service dataset and see how we can you an LLM to call functions to interact with the data.\n",
    "\n",
    "First, we print out the a sample and look at the conversation, that we'll be using to create a sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Hello, thank you for contacting BrownBox customer support. My name is Alex, how can I assist you today?\n",
      "Customer: Hi, I'm calling about my order for a water purifier. I received it yesterday, but it's not working correctly. I want to return it and get a refund.\n",
      "Agent: I'm sorry to hear that. I'll be happy to help you with that. Can you please provide me with your order number?\n",
      "Customer: Sure, it's 12345.\n",
      "Agent: Thank you for the information. May I know the reason for the return?\n",
      "Customer: As I mentioned earlier, the product is not working correctly. I want to return it and get a refund.\n",
      "Agent: I'm sorry for the inconvenience. We would be happy to process your return and refund. However, since you have opted for Cash on Delivery, it will take some time to process your refund. Our refund timelines for Cash on Delivery returns are usually within 7-14 business days from the date of pickup. \n",
      "Customer: What? That's too long. Why does it take so much time?\n",
      "Agent: I understand your frustration, but the refund process takes time as we have to verify the product's condition and ensure that it's unused and in its original packaging. Once we receive the product, we will initiate the refund process, and it will take 7-14 business days for the refund to reflect in your account.\n",
      "Customer: This is unacceptable. I need the refund immediately. Can't you do anything about it?\n",
      "Agent: I'm sorry, but we cannot expedite the refund process. However, I can assure you that we will process your refund as soon as possible. \n",
      "Customer: Can you at least tell me the status of my refund?\n",
      "Agent: Sure, I can check the status of your refund. Please allow me a moment to check that for you.\n",
      "(Customer is put on hold for a few minutes)\n",
      "Agent: Thank you for waiting. I have checked your refund status, and I see that your return has been received by our team. The refund process has been initiated, and it will reflect in your account within 7-14 business days.\n",
      "Customer: Alright, I understand. Is there anything else I need to do?\n",
      "Agent: No, you don't have to do anything else. Our team will process your refund, and you will receive an email confirmation once it's done. \n",
      "Customer: Okay, thank you for your help.\n",
      "Agent: You're welcome. I apologize for the inconvenience caused. Is there anything else I can assist you with?\n",
      "Customer: No, that's all. \n",
      "Agent: Alright, please feel free to contact us if you have any further questions or concerns. Have a great day!\n",
      "Customer: You too. Bye.\n",
      "Agent: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "# load the customer service chatbot dataset\n",
    "dialogue_data = load_dataset(cwd + \"/data/customer_service_chatbot\", cache_dir=\"./cache\")[\"train\"]\n",
    "sample = dialogue_data[6] # load a sample \n",
    "dialogue_string = sample[\"conversation\"].replace(\"\\n\\n\", \"\\n\") # remove double newlines\n",
    "print (dialogue_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a data class\n",
    "For the LLM to extract features from these dialogues, we create a data class \"Record\" which describes the desired format and features that should be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, fields\n",
    "dataclass_schema_representation = '''\n",
    "@dataclass\n",
    "class Record:\n",
    "    agent_name : str # The agent name\n",
    "    customer_email : str # customer email if provided, else ''\n",
    "    customer_order : str # The customer order number if provided, else ''\n",
    "    customer_phone : str # the customer phone number if provided, else ''\n",
    "    customer_sentiment : str # Overall customer sentiment, either 'frustrated', or 'happy'. Always MUST have a value.\n",
    "'''\n",
    "\n",
    "# Let's call exec to insert the dataclass into our python interpreter so it understands this. \n",
    "exec(dataclass_schema_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a test data base\n",
    "This makes it easy for the LLM to add records to a database. We will now initialize a test database where the extracted features will be stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_db():\n",
    "    import sqlite3\n",
    "\n",
    "    # Connect to SQLite database (or create it if it doesn't exist)\n",
    "    conn = sqlite3.connect('extracted_test.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fixed table name\n",
    "    table_name = \"customer_information\"\n",
    "\n",
    "    # Fixed schema\n",
    "    columns = \"\"\"\n",
    "    id INTEGER PRIMARY KEY, \n",
    "    agent_name TEXT, \n",
    "    customer_email TEXT, \n",
    "    customer_order TEXT, \n",
    "    customer_phone TEXT, \n",
    "    customer_sentiment TEXT\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the table name is enclosed in quotes if it contains special characters\n",
    "    quoted_table_name = f'\"{table_name}\"'\n",
    "\n",
    "    # Check if a table with the exact name already exists\n",
    "    cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name={quoted_table_name}\")\n",
    "    if cursor.fetchone():\n",
    "        print(f\"Table {table_name} already exists.\")\n",
    "    else:\n",
    "        # Create the new table with the fixed schema\n",
    "        cursor.execute(f'''CREATE TABLE {quoted_table_name} ({columns})''')\n",
    "        print(f\"Table {table_name} created successfully.\")\n",
    "\n",
    "    # Commit the transaction and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table customer_information created successfully.\n"
     ]
    }
   ],
   "source": [
    "!rm extracted_test.db\n",
    "initialize_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating prompts for the LLM\n",
    "\n",
    "We need a function which allows us to populate the database. This functions structure is included in the prompt to ensure the function's proper use of the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def update_knowledge(results_list : List[Record]):\n",
    "    \"\"\"\n",
    "    Registers the information necessary\n",
    "    \"\"\"\n",
    "    import sqlite3\n",
    "    from sqlite3 import ProgrammingError\n",
    "\n",
    "    # Reconnect to the existing SQLite database\n",
    "    conn = sqlite3.connect('extracted_test.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fixed table name\n",
    "    table_name = \"customer_information\"\n",
    "\n",
    "    # Prepare SQL for inserting data with fixed column names\n",
    "    column_names = \"agent_name, customer_email, customer_order, customer_phone, customer_sentiment\"\n",
    "    placeholders = \", \".join([\"?\"] * 5) \n",
    "    sql = f\"INSERT INTO {table_name} ({column_names}) VALUES ({placeholders})\"\n",
    "\n",
    "    # Insert each record\n",
    "    for record in results_list:\n",
    "        try:\n",
    "            record_values = tuple(getattr(record, f.name) for f in fields(record))\n",
    "            cursor.execute(sql, record_values)\n",
    "        except ProgrammingError as e:\n",
    "            print(f\"Error with record. {e}\")\n",
    "            continue\n",
    "\n",
    "    # Commit the changes and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Records inserted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this is where it becomes interesting. We'll define a prompt which enables the LLM to extract the information. For this we take the signature and the docstring of the update_knowledge function as well as the data class \"Record\" to provide more information for the LLM on how to call the function update_knowledge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@dataclass\n",
      "class Record:\n",
      "    agent_name : str # The agent name\n",
      "    customer_email : str # customer email if provided, else ''\n",
      "    customer_order : str # The customer order number if provided, else ''\n",
      "    customer_phone : str # the customer phone number if provided, else ''\n",
      "    customer_sentiment : str # Overall customer sentiment, either 'frustrated', or 'happy'. Always MUST have a value.\n",
      "\n",
      "Function:\n",
      "update_knowledge(results_list: List[Record])\n",
      "    \"\"\"\n",
      "    Registers the information necessary\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "User Query:\n",
      "Agent: Hello, thank you for contacting BrownBox customer support. My name is Alex, how can I assist you today?\n",
      "Customer: Hi, I'm calling about my order for a water purifier. I received it yesterday, but it's not working correctly. I want to return it and get a refund.\n",
      "Agent: I'm sorry to hear that. I'll be happy to help you with that. Can you please provide me with your order number?\n",
      "Customer: Sure, it's 12345.\n",
      "Agent: Thank you for the information. May I know the reason for the return?\n",
      "Customer: As I mentioned earlier, the product is not working correctly. I want to return it and get a refund.\n",
      "Agent: I'm sorry for the inconvenience. We would be happy to process your return and refund. However, since you have opted for Cash on Delivery, it will take some time to process your refund. Our refund timelines for Cash on Delivery returns are usually within 7-14 business days from the date of pickup. \n",
      "Customer: What? That's too long. Why does it take so much time?\n",
      "Agent: I understand your frustration, but the refund process takes time as we have to verify the product's condition and ensure that it's unused and in its original packaging. Once we receive the product, we will initiate the refund process, and it will take 7-14 business days for the refund to reflect in your account.\n",
      "Customer: This is unacceptable. I need the refund immediately. Can't you do anything about it?\n",
      "Agent: I'm sorry, but we cannot expedite the refund process. However, I can assure you that we will process your refund as soon as possible. \n",
      "Customer: Can you at least tell me the status of my refund?\n",
      "Agent: Sure, I can check the status of your refund. Please allow me a moment to check that for you.\n",
      "(Customer is put on hold for a few minutes)\n",
      "Agent: Thank you for waiting. I have checked your refund status, and I see that your return has been received by our team. The refund process has been initiated, and it will reflect in your account within 7-14 business days.\n",
      "Customer: Alright, I understand. Is there anything else I need to do?\n",
      "Agent: No, you don't have to do anything else. Our team will process your refund, and you will receive an email confirmation once it's done. \n",
      "Customer: Okay, thank you for your help.\n",
      "Agent: You're welcome. I apologize for the inconvenience caused. Is there anything else I can assist you with?\n",
      "Customer: No, that's all. \n",
      "Agent: Alright, please feel free to contact us if you have any further questions or concerns. Have a great day!\n",
      "Customer: You too. Bye.\n",
      "Agent: Goodbye!<human_end>\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "prompt = \"\\n\" + dialogue_string\n",
    "\n",
    "signature = inspect.signature(update_knowledge)\n",
    "signature = str(signature).replace(\"__main__.Record\", \"Record\")\n",
    "docstring = update_knowledge.__doc__\n",
    "\n",
    "raven_prompt = f'''{dataclass_schema_representation}\\nFunction:\\n{update_knowledge.__name__}{signature}\\n    \"\"\"{docstring}\"\"\"\\n\\n\\nUser Query:{prompt}<human_end>'''\n",
    "print (raven_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now query the LLM to extract the features for the data class and the database. The LLM correctly populates the record and passes it to the update_knowledge function. We use the eval() function to run the function and to add the record to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update_knowledge(results_list=[Record(agent_name='Alex', customer_email='', customer_order='12345', customer_phone='', customer_sentiment='frustrated')])\n"
     ]
    }
   ],
   "source": [
    "from utils import query_raven\n",
    "raven_call = query_raven(raven_prompt)\n",
    "print (raven_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "To check the new entry, we need a function to interact with the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "def execute_sql(sql: str):\n",
    "    \"\"\" Runs SQL code for the given schema. Make sure to properly leverage the schema to answer the user's question in the best way possible. \"\"\"\n",
    "    # Fixed table name, assuming it's not dynamically generated anymore\n",
    "    table_name = \"customer_information\"\n",
    "\n",
    "    # Establish a connection to the database\n",
    "    conn = sqlite3.connect('extracted_test.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute the SQL statement\n",
    "    cursor.execute(sql)\n",
    "\n",
    "    # Initialize an empty list to hold query results\n",
    "    results = []\n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    print(\"Query operation executed successfully. Number of rows returned:\", len(results))\n",
    "\n",
    "    # Close the connection to the database\n",
    "    conn.close()\n",
    "\n",
    "    # Return the results for SELECT operations; otherwise, return an empty list\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing SQL: \n",
      "    SELECT agent_name \n",
      "        FROM customer_information\n",
      "        WHERE customer_sentiment = \"frustrated\"\n",
      "    \n",
      "Query operation executed successfully. Number of rows returned: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Alex',)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "    SELECT agent_name \n",
    "        FROM customer_information\n",
    "        WHERE customer_sentiment = \"frustrated\"\n",
    "    '''\n",
    "# Print the final SQL command for debugging\n",
    "print(\"Executing SQL:\", sql)\n",
    "\n",
    "execute_sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a database for Part 2\n",
    "I have created a python file which allows the user to create a database called extracted.db. It can be called in the terminal using\n",
    "\n",
    "```\n",
    "python3 createDatabase.py --n=10\n",
    "``` \n",
    "with n being the number of records created from the original dataset, which contains 1000 records.\n",
    "\n",
    "**Note:** Everything so far was done using a test database called extracted_test.db. From now on, we'll use the database that is created using the script (specifically with n=10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "The second part of the project contains the following steps:\n",
    "* Exploring the newly created  created by the LLM\n",
    "* Exploring the Chinook database\n",
    "* Creating more complex queries to test the performance of the LLM\n",
    "\n",
    "For the database exploration, we'll use the functions execute_sql, get_query that are defined in utils.py. These functions are more versatile letting the user choose the database. For more information, check out my [repo](https://github.com/SebastianGhafafian/NexusLLM) on Github. \n",
    "\n",
    "\n",
    "## Exploring the Customer Service database\n",
    "\n",
    "\n",
    "Let's check out the newly created database extracted.db and at the same time evaluate the LLM's performance on creating SQL queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import execute_sql, get_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells below are three questions. The first one creates an overview of the database. The LLM performed well in extracting the data from the dialogue information. For entry 4, it does not identify the name correctly (\"BrownBox\" although the agent name was never mentioned). This could potentially be fixed by providing a more specific prompt in that regard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT * FROM customer_information', database_path='data/extracted.db')\n",
      "Query operation executed successfully. Number of rows returned: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'Tom', 'johndoe@email.com', '', '+1 123-456-7890', 'happy'),\n",
       " (2, 'Alex', '', '789101', '', 'happy'),\n",
       " (3, 'Sarah', 'jane.doe@email.com', '987654', '', 'happy'),\n",
       " (4, 'BrownBox', 'john.doe@gmail.com', 'BB98765432', '123-456-7890', 'happy'),\n",
       " (5, 'Sarah', '', 'BB123456', '', 'frustrated'),\n",
       " (6, 'Alex', 'johnsmith@email.com', '', '123-456-7890', 'happy'),\n",
       " (7, 'Alex', '', '12345', '', 'frustrated'),\n",
       " (8, 'Rachel', '', '', '', 'happy'),\n",
       " (9, 'Sarah', '', '#98765', '', 'happy'),\n",
       " (10, 'Sarah', 'jane@email.com', '', '9876543210', 'frustrated')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Give me all the entries from the database?\"\n",
    "\n",
    "raven_call, prompt = get_query(database_path = \"data/extracted.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before checking the next two questions, let's check out the prompt passed to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "\n",
      "    \n",
      "CREATE TABLE customer_information (\n",
      "\tid INTEGER, \n",
      "\tagent_name TEXT, \n",
      "\tcustomer_email TEXT, \n",
      "\tcustomer_order TEXT, \n",
      "\tcustomer_phone TEXT, \n",
      "\tcustomer_sentiment TEXT, \n",
      "\tPRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from customer_information table:\n",
      "id\tagent_name\tcustomer_email\tcustomer_order\tcustomer_phone\tcustomer_sentiment\n",
      "1\tTom\tjohndoe@email.com\t\t+1 123-456-7890\thappy\n",
      "2\tAlex\t\t789101\t\thappy\n",
      "3\tSarah\tjane.doe@email.com\t987654\t\thappy\n",
      "*/\n",
      "    \n",
      "Function:\n",
      "execute_sql(sql: str, database_path: str)\n",
      "    \"\"\"\n",
      "    Runs SQL code for the given schema and database. Make sure to properly leverage the schema to answer the user's question in the best way possible. \n",
      "    Pay attention to use only the the column names of that belong to a table which are described in the schema description.\n",
      "    Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "\n",
      "    \n",
      "    Args:\n",
      "        sql: SQL code to run\n",
      "        database_name: name of the database to run the SQL code\n",
      "    Returns:\n",
      "        results: list of tuples containing the results of the SQL query\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "Database Name: data/extracted.db\n",
      "User Query: Give me all the entries from the database?<human_end>\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prompt allows the LLM to gain insights over the used database. Yet, this also creates limitations for large databases containing numerous tables in combination with LLMs allowing for a limited amount of input tokens.\n",
    "\n",
    "Let's continue to see how the LLM performs. The second question probes the LLM with a more challenging question. The LLM correctly creates a WHERE statement. It manages to understand what a gmail email adress is, i.e. a adress that ends in gmail.com which is checked using the LIKE statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT customer_email FROM customer_information WHERE customer_email LIKE \"%gmail.com\"', database_path='data/extracted.db')\n",
      "Query operation executed successfully. Number of rows returned: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('john.doe@gmail.com',)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the names of customers with a gmail email adress?\"\n",
    "raven_call, prompt = get_query(database_path = \"data/extracted.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the third question. the LLM returns an empty list, although there is a phone number that starts with +1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT * FROM customer_information WHERE customer_phone LIKE \"%-011-%\"', database_path='data/extracted.db')\n",
      "Query operation executed successfully. Number of rows returned: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'Give me all the entries from the database with an American phone number?' # outputs wrong results\n",
    "raven_call, prompt = get_query(database_path = \"data/extracted.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By providing a more detailed question, the LLM is able to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT * FROM customer_information WHERE customer_phone LIKE \"+1%\"', database_path='data/extracted.db')\n",
      "Query operation executed successfully. Number of rows returned: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'Tom', 'johndoe@email.com', '', '+1 123-456-7890', 'happy')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'Give me all the entries from the database with an American phone number, which starts with \"+1\"?'\n",
    "raven_call, prompt = get_query(database_path = \"data/extracted.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Chinook database\n",
    "\n",
    "The chinook database is a classic example database which represents a digital media store. It contains mutliple tables. This allows us to really explore the abilities of LLMs for complex tasks. Let's create three queries of increasing complexity to explore the database. The LLM does a good job in translating the questions into SQL queries allowing for a quick overview.\n",
    "![Chinook](img/chinook_db.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT name FROM sqlite_master WHERE type = \"table\"', database_path='data/Chinook.db')\n",
      "Query operation executed successfully. Number of rows returned: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Album',),\n",
       " ('Artist',),\n",
       " ('Customer',),\n",
       " ('Employee',),\n",
       " ('Genre',),\n",
       " ('Invoice',),\n",
       " ('InvoiceLine',),\n",
       " ('MediaType',),\n",
       " ('Playlist',),\n",
       " ('PlaylistTrack',),\n",
       " ('Track',)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What the tables in the database?\"\n",
    "raven_call, prompt = get_query(database_path = \"data/Chinook.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT * FROM Artist ORDER BY Name ASC LIMIT 15', database_path='data/Chinook.db')\n",
      "Query operation executed successfully. Number of rows returned: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(43, 'A Cor Do Som'),\n",
       " (1, 'AC/DC'),\n",
       " (230, 'Aaron Copland & London Symphony Orchestra'),\n",
       " (202, 'Aaron Goldberg'),\n",
       " (214, 'Academy of St. Martin in the Fields & Sir Neville Marriner'),\n",
       " (215,\n",
       "  'Academy of St. Martin in the Fields Chamber Ensemble & Sir Neville Marriner'),\n",
       " (222,\n",
       "  'Academy of St. Martin in the Fields, John Birch, Sir Neville Marriner & Sylvia McNair'),\n",
       " (257,\n",
       "  'Academy of St. Martin in the Fields, Sir Neville Marriner & Thurston Dart'),\n",
       " (239,\n",
       "  'Academy of St. Martin in the Fields, Sir Neville Marriner & William Bennett'),\n",
       " (2, 'Accept'),\n",
       " (260, 'Adrian Leaper & Doreen de Feis'),\n",
       " (3, 'Aerosmith'),\n",
       " (161, \"Aerosmith & Sierra Leone's Refugee Allstars\"),\n",
       " (197, 'Aisha Duo'),\n",
       " (4, 'Alanis Morissette')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Give me 15 the entries from the artist table? Sort the names alphabetically.\"\n",
    "raven_call, prompt = get_query(database_path = \"data/Chinook.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT Composer, COUNT(TrackId) AS NumberOfTracks FROM Track GROUP BY Composer ORDER BY NumberOfTracks DESC LIMIT 5', database_path='data/Chinook.db')\n",
      "Query operation executed successfully. Number of rows returned: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(None, 977),\n",
       " ('Steve Harris', 80),\n",
       " ('U2', 44),\n",
       " ('Jagger/Richards', 35),\n",
       " ('Billy Corgan', 31)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How many tracks did each composer have? Only show the 5 most common composers.\"\n",
    "raven_call, prompt = get_query(database_path = \"data/Chinook.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushing the LLM - Hallucinations\n",
    "\n",
    "We have now seen that the LLM is capable of performing simple tasks to extract data from a database. One major problem with LLM are hallicinations meaning wrong outputs, which in this case can be devided into two types:\n",
    "* Wrong syntax leading to a error, e.g. using functions of a different SQL dialect\n",
    "* Correct syntax yet output created is semantically wrong, e.g. the query is wrong.\n",
    "\n",
    "Let's see what it can do to for more complicated questions. We'll be using the Chinook database as it contains multiple tables.\n",
    "\n",
    "## Simple Joins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT Genre.Name, Track.Name, Track.Milliseconds FROM Track JOIN Genre ON Track.GenreId = Genre.GenreId ORDER BY Track.Milliseconds DESC LIMIT 1', database_path='data/Chinook.db')\n",
      "Query operation executed successfully. Number of rows returned: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('TV Shows', 'Occupation / Precipice', 5286953)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the genre of the track with the longest duration?\" \n",
    "\n",
    "raven_call, prompt = get_query(database_path = \"data/Chinook.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT Track.Name, Genre.Name FROM Track JOIN Genre ON Track.GenreId = Genre.GenreId LIMIT 10', database_path='data/Chinook.db')\n",
      "Query operation executed successfully. Number of rows returned: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('For Those About To Rock (We Salute You)', 'Rock'),\n",
       " ('Balls to the Wall', 'Rock'),\n",
       " ('Fast As a Shark', 'Rock'),\n",
       " ('Restless and Wild', 'Rock'),\n",
       " ('Princess of the Dawn', 'Rock'),\n",
       " ('Put The Finger On You', 'Rock'),\n",
       " (\"Let's Get It Up\", 'Rock'),\n",
       " ('Inject The Venom', 'Rock'),\n",
       " ('Snowballed', 'Rock'),\n",
       " ('Evil Walks', 'Rock')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"List the tracks and their genre? List 10 entries\"\n",
    "\n",
    "raven_call, prompt = get_query(database_path = \"data/Chinook.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT Album.Title, COUNT(Track.TrackId) AS TrackCount FROM Album JOIN Track ON Album.AlbumId = Track.AlbumId GROUP BY Album.Title ORDER BY TrackCount DESC LIMIT 1;', database_path='data/Chinook.db')\n",
      "Query operation executed successfully. Number of rows returned: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Greatest Hits', 57)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Which album has the most tracks?\"\n",
    "raven_call, prompt = get_query(database_path = \"data/Chinook.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT Album.Title, SUM(Track.Milliseconds) AS TotalPlaytime FROM Album JOIN Track ON Album.AlbumId = Track.AlbumId GROUP BY Album.Title ORDER BY TotalPlaytime ASC LIMIT 1', database_path='data/Chinook.db')\n",
      "Query operation executed successfully. Number of rows returned: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(\"Liszt - 12 Études D'Execution Transcendante\", 51780)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Which album has shortest total playtime of milliseconds?\"\n",
    "raven_call, prompt = get_query(database_path = \"data/Chinook.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. It seems to be performing quite well on simple joins. Let's look at queries multiple joins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple joins\n",
    "How about the following question: Get the artist name and genre of the each track? Limit the output to 10 entries.\n",
    "\n",
    "It produces an output, yet on closer inspection, the parts of the demanded output is missing, namely the artist name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT Track.Name, Genre.Name FROM Track JOIN Genre ON Track.GenreId = Genre.GenreId LIMIT 10', database_path='data/Chinook.db')\n",
      "Query operation executed successfully. Number of rows returned: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('For Those About To Rock (We Salute You)', 'Rock'),\n",
       " ('Balls to the Wall', 'Rock'),\n",
       " ('Fast As a Shark', 'Rock'),\n",
       " ('Restless and Wild', 'Rock'),\n",
       " ('Princess of the Dawn', 'Rock'),\n",
       " ('Put The Finger On You', 'Rock'),\n",
       " (\"Let's Get It Up\", 'Rock'),\n",
       " ('Inject The Venom', 'Rock'),\n",
       " ('Snowballed', 'Rock'),\n",
       " ('Evil Walks', 'Rock')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Get the album name and genre of the each track? Limit the output to 10 entries\" #semantically incorrect\n",
    "\n",
    "raven_call, prompt = get_query(database_path = \"data/Chinook.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe it helps to rewrite the question and to provide more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT Album.Title, Genre.Name FROM Album JOIN Genre ON Album.GenreId = Genre.GenreId JOIN Track ON Album.AlbumId = Track.AlbumId', database_path='data/Chinook.db')\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "no such column: Album.GenreId",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m raven_call, prompt \u001b[38;5;241m=\u001b[39m get_query(database_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/Chinook.db\u001b[39m\u001b[38;5;124m\"\u001b[39m, question \u001b[38;5;241m=\u001b[39m question)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(raven_call)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraven_call\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Projects/NexusLLM/utils.py:46\u001b[0m, in \u001b[0;36mexecute_sql\u001b[0;34m(sql, database_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Execute the SQL statement\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Initialize an empty list to hold query results\u001b[39;00m\n\u001b[1;32m     49\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such column: Album.GenreId"
     ]
    }
   ],
   "source": [
    "question = \"Get the album name of each track and its genre name? This requires a join of the Album table, the Genre table and the Track table\" #syntax error\n",
    "\n",
    "raven_call, prompt = get_query(database_path = \"data/Chinook.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, this time it tries to query a column that doesn't exist: Album.GenreId.\n",
    "\n",
    "The following question is answered correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT Playlist.Name, SUM(Track.Milliseconds) AS TotalMilliseconds FROM Playlist JOIN PlaylistTrack ON Playlist.PlaylistId = PlaylistTrack.PlaylistId JOIN Track ON PlaylistTrack.TrackId = Track.TrackId GROUP BY Playlist.Name ORDER BY TotalMilliseconds DESC LIMIT 1;', database_path='data/Chinook.db')\n",
      "Query operation executed successfully. Number of rows returned: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Music', 1755366166)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the name of the playlist with the longest playtime in milliseconds\" #lets check this complex query\n",
    "\n",
    "raven_call, prompt = get_query(database_path = \"data/Chinook.db\", question = question)\n",
    "print(raven_call)\n",
    "eval(raven_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This project explore the capabilities of the Nexus Raven LLM to call functions and to extract data from text. The LLM was then used to create SQL queries. The final performance of the LLM is very robust for simpler queries. I am sure that more elaborate prompts will help the LLM to get more accurate results on more complicated questions. Although, the expected performance increase in prompt engineering is limited. The occurance of hallucinations seems to rapidly increase for more complex queries involving multiple joins. A common mistake is that the LLM starts to use column names of the wrong table, i.e. Album.GenreId, or it simply ignores the part of the query. \n",
    "\n",
    "The created functions from this project come in very handy in first interacting with a unknown database performing easier queries. Yet, the prompt should always be closely inspected in order to gage the received answers. It only needs the following code block which can be copied in a Jupyter notebook to get a first overview of a new data base. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_sql(sql='SELECT LastName, FirstName, Email FROM Employee', database_path='./data/Chinook.db')\n",
      "Query operation executed successfully. Number of rows returned: 8\n",
      "[('Adams', 'Andrew', 'andrew@chinookcorp.com'), ('Edwards', 'Nancy', 'nancy@chinookcorp.com'), ('Peacock', 'Jane', 'jane@chinookcorp.com'), ('Park', 'Margaret', 'margaret@chinookcorp.com'), ('Johnson', 'Steve', 'steve@chinookcorp.com'), ('Mitchell', 'Michael', 'michael@chinookcorp.com'), ('King', 'Robert', 'robert@chinookcorp.com'), ('Callahan', 'Laura', 'laura@chinookcorp.com')]\n"
     ]
    }
   ],
   "source": [
    "from utils import execute_sql, get_query\n",
    "\n",
    "question = \"What is the name and email of each employee?\"\n",
    "raven_call, prompt = get_query(\"./data/Chinook.db\", question)   \n",
    "print(raven_call)\n",
    "print(eval(raven_call))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the performance quantitatively, we would need a evaluation set of question/query pairs, which I want to explore in my next project. That would enable to properly evaluate measures to increase the performance of the LLM. This project will include iteratively improving the model on a specific database by creating evaluations sets, and memory tuning, which reduces hallucinations by embedding facts directly into the weights of the model. This process will allow for the introductions of some sort of determinism in the probabilistic LLM without sacrificing generalization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
